{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\iNeuron_Projects\\\\End_to_End_ML_Dental_Implant_Sandblasting\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\iNeuron_Projects\\\\End_to_End_ML_Dental_Implant_Sandblasting'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-18 11:41:19,545: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-09-18 11:41:19,554: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-09-18 11:41:19,556: INFO: common: created directory at: artifacts]\n",
      "[2024-09-18 11:41:19,558: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2024-09-18 11:41:19,601: INFO: 1159620672: Data loaded from artifacts\\data_ingestion\\Sandblasting-Condition.csv]\n",
      "[2024-09-18 11:41:19,627: INFO: 1159620672: Data Head: \n",
      "   angle_sandblasting  pressure_sandblasting_bar  temperature_acid_etching  \\\n",
      "0                  30                          3                        25   \n",
      "1                  40                          3                        25   \n",
      "2                  50                          3                        25   \n",
      "3                  30                          3                        25   \n",
      "4                  30                          3                        25   \n",
      "\n",
      "   time_acid_etching_min  voltage_anodizing_v  time_anodizing_min  \\\n",
      "0                      3                   80                   1   \n",
      "1                      3                   80                   1   \n",
      "2                      3                   80                   1   \n",
      "3                      6                   80                   1   \n",
      "4                      9                   80                   1   \n",
      "\n",
      "   sa_surface_roughness_micrometer  cell_viability_percent  \\\n",
      "0                            0.746                      75   \n",
      "1                            0.813                      70   \n",
      "2                            0.952                      65   \n",
      "3                            0.950                      77   \n",
      "4                            1.020                      75   \n",
      "\n",
      "   Result_Passed_1_Failed_0  \n",
      "0                         0  \n",
      "1                         0  \n",
      "2                         0  \n",
      "3                         0  \n",
      "4                         0  ]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 198 entries, 0 to 197\n",
      "Data columns (total 9 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   angle_sandblasting               198 non-null    int64  \n",
      " 1   pressure_sandblasting_bar        198 non-null    int64  \n",
      " 2   temperature_acid_etching         198 non-null    int64  \n",
      " 3   time_acid_etching_min            198 non-null    int64  \n",
      " 4   voltage_anodizing_v              198 non-null    int64  \n",
      " 5   time_anodizing_min               198 non-null    int64  \n",
      " 6   sa_surface_roughness_micrometer  198 non-null    float64\n",
      " 7   cell_viability_percent           198 non-null    int64  \n",
      " 8   Result_Passed_1_Failed_0         198 non-null    int64  \n",
      "dtypes: float64(1), int64(8)\n",
      "memory usage: 14.0 KB\n",
      "[2024-09-18 11:41:19,655: INFO: 1159620672: Data Info: \n",
      "None]\n",
      "[2024-09-18 11:41:19,717: INFO: 1159620672: Data Description: \n",
      "       angle_sandblasting  pressure_sandblasting_bar  \\\n",
      "count          198.000000                 198.000000   \n",
      "mean            37.121212                   4.050505   \n",
      "std              8.016193                   0.859391   \n",
      "min             30.000000                   3.000000   \n",
      "25%             30.000000                   3.000000   \n",
      "50%             30.000000                   4.000000   \n",
      "75%             40.000000                   5.000000   \n",
      "max             50.000000                   5.000000   \n",
      "\n",
      "       temperature_acid_etching  time_acid_etching_min  voltage_anodizing_v  \\\n",
      "count                198.000000             198.000000           198.000000   \n",
      "mean                  49.621212               5.818182            99.393939   \n",
      "std                   21.738710               2.353801            16.235462   \n",
      "min                   25.000000               3.000000            80.000000   \n",
      "25%                   25.000000               3.000000            80.000000   \n",
      "50%                   50.000000               6.000000           100.000000   \n",
      "75%                   75.000000               9.000000           120.000000   \n",
      "max                   75.000000               9.000000           120.000000   \n",
      "\n",
      "       time_anodizing_min  sa_surface_roughness_micrometer  \\\n",
      "count          198.000000                       198.000000   \n",
      "mean             5.176768                         2.086010   \n",
      "std              3.694428                         0.760536   \n",
      "min              1.000000                         0.746000   \n",
      "25%              1.000000                         1.450000   \n",
      "50%              5.000000                         2.156000   \n",
      "75%             10.000000                         2.623500   \n",
      "max             10.000000                         3.497000   \n",
      "\n",
      "       cell_viability_percent  Result_Passed_1_Failed_0  \n",
      "count              198.000000                198.000000  \n",
      "mean                77.126263                  0.116162  \n",
      "std                  8.858689                  0.321231  \n",
      "min                 62.000000                  0.000000  \n",
      "25%                 70.000000                  0.000000  \n",
      "50%                 76.000000                  0.000000  \n",
      "75%                 83.000000                  0.000000  \n",
      "max                 96.000000                  1.000000  ]\n",
      "[2024-09-18 11:41:19,726: INFO: 1159620672: Missing values handled using KNN imputation]\n",
      "[2024-09-18 11:41:19,775: INFO: 1159620672: Number of components after PCA: 6]\n",
      "[2024-09-18 11:41:19,791: INFO: 1159620672: Number of features selected for Sa after RFE: 6]\n",
      "[2024-09-18 11:41:19,793: INFO: 1159620672: Number of features selected for CV after RFE: 6]\n",
      "[2024-09-18 11:41:19,816: INFO: 1159620672: Training data saved: Sa - (158, 6), CV - (158, 6)]\n",
      "[2024-09-18 11:41:19,825: INFO: 1159620672: Testing data saved: Sa - (40, 6), CV - (40, 6)]\n",
      "[2024-09-18 11:41:19,830: INFO: 1159620672: Data transformation and splitting completed successfully.]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.impute import KNNImputer\n",
    "from xgboost import XGBRegressor\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from Dental_Implant_Sandblasting import logger\n",
    "from Dental_Implant_Sandblasting.utils.common import read_yaml, create_directories\n",
    "from Dental_Implant_Sandblasting.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH, SCHEMA_FILE_PATH\n",
    "\n",
    "# Data class for Data Transformation configuration\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    transformed_train_dir: Path\n",
    "    transformed_test_dir: Path\n",
    "    test_size: float\n",
    "    random_state: int\n",
    "    polynomial_features_degree: int\n",
    "    scaling_method: str\n",
    "    lasso_max_iter: int\n",
    "    knn_n_neighbors: int\n",
    "\n",
    "# Configuration Manager class for loading configurations\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH, schema_filepath=SCHEMA_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config['artifacts_root']])\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config['data_transformation']\n",
    "        params = self.params['data_transformation']\n",
    "        create_directories([config['root_dir']])\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=Path(config['root_dir']),\n",
    "            data_path=Path(config['data_path']),\n",
    "            transformed_train_dir=Path(config['transformed_train_path']),\n",
    "            transformed_test_dir=Path(config['transformed_test_path']),\n",
    "            test_size=params['test_size'],\n",
    "            random_state=params['random_state'],\n",
    "            polynomial_features_degree=params['polynomial_features_degree'],\n",
    "            scaling_method=params['scaling_method'],\n",
    "            lasso_max_iter=params['lasso_max_iter'],\n",
    "            knn_n_neighbors=params['knn_n_neighbors']\n",
    "        )\n",
    "        return data_transformation_config\n",
    "\n",
    "# Data Transformation class\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def load_data(self):\n",
    "        data = pd.read_csv(self.config.data_path)\n",
    "        logger.info(f\"Data loaded from {self.config.data_path}\")\n",
    "\n",
    "        # Basic Data Exploration\n",
    "        logger.info(f\"Data Head: \\n{data.head()}\")\n",
    "        logger.info(f\"Data Info: \\n{data.info()}\")\n",
    "        logger.info(f\"Data Description: \\n{data.describe()}\")\n",
    "\n",
    "        return data\n",
    "\n",
    "    def preprocess_data(self, data):\n",
    "        # Convert columns to numeric, forcing any errors to NaN\n",
    "        for col in data.columns:\n",
    "            data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "        # Use KNN Imputer to handle missing values\n",
    "        imputer = KNNImputer(n_neighbors=self.config.knn_n_neighbors)\n",
    "        data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "        logger.info(\"Missing values handled using KNN imputation\")\n",
    "        return data_imputed\n",
    "\n",
    "    def feature_engineering(self, data):\n",
    "        # Define feature and target columns\n",
    "        feature_columns = [\n",
    "            'angle_sandblasting',\n",
    "            'pressure_sandblasting_bar',\n",
    "            'temperature_acid_etching',\n",
    "            'time_acid_etching_min',\n",
    "            'voltage_anodizing_v',\n",
    "            'time_anodizing_min'\n",
    "        ]\n",
    "        target_column_sa = 'sa_surface_roughness_micrometer'\n",
    "        target_column_cv = 'cell_viability_percent'\n",
    "\n",
    "        X = data[feature_columns]\n",
    "        y_sa = data[target_column_sa]\n",
    "        y_cv = data[target_column_cv]\n",
    "\n",
    "        # Apply PolynomialFeatures\n",
    "        poly = PolynomialFeatures(degree=self.config.polynomial_features_degree, include_bias=False)\n",
    "        X_poly = poly.fit_transform(X)\n",
    "\n",
    "        # Standardize the features using RobustScaler\n",
    "        scaler = RobustScaler()\n",
    "        X_scaled = scaler.fit_transform(X_poly)\n",
    "\n",
    "        # Apply PCA for dimensionality reduction\n",
    "        pca = PCA(n_components=0.95)\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "        logger.info(f\"Number of components after PCA: {X_pca.shape[1]}\")\n",
    "\n",
    "        # Feature Selection using RFE with Lasso\n",
    "        lasso_model = Lasso(alpha=0.01, max_iter=self.config.lasso_max_iter)\n",
    "\n",
    "        rfe_sa = RFE(lasso_model, n_features_to_select=10)\n",
    "        X_sa_rfe = rfe_sa.fit_transform(X_pca, y_sa)\n",
    "\n",
    "        rfe_cv = RFE(lasso_model, n_features_to_select=10)\n",
    "        X_cv_rfe = rfe_cv.fit_transform(X_pca, y_cv)\n",
    "\n",
    "        logger.info(f\"Number of features selected for Sa after RFE: {X_sa_rfe.shape[1]}\")\n",
    "        logger.info(f\"Number of features selected for CV after RFE: {X_cv_rfe.shape[1]}\")\n",
    "\n",
    "        return X_sa_rfe, X_cv_rfe, y_sa, y_cv\n",
    "\n",
    "    def train_test_splitting(self, X_sa_rfe, X_cv_rfe, y_sa, y_cv):\n",
    "        # Split the data into training and testing sets for Surface Roughness (Sa) and Cell Viability (CV)\n",
    "        X_train_sa, X_test_sa, y_sa_train, y_sa_test = train_test_split(X_sa_rfe, y_sa, test_size=self.config.test_size, random_state=self.config.random_state)\n",
    "        X_train_cv, X_test_cv, y_cv_train, y_cv_test = train_test_split(X_cv_rfe, y_cv, test_size=self.config.test_size, random_state=self.config.random_state)\n",
    "\n",
    "        # Ensure directories exist before saving the files\n",
    "        os.makedirs(self.config.transformed_train_dir, exist_ok=True)\n",
    "        os.makedirs(self.config.transformed_test_dir, exist_ok=True)\n",
    "\n",
    "        # Save the transformed datasets\n",
    "        train_data_sa = pd.DataFrame(X_train_sa)\n",
    "        train_data_cv = pd.DataFrame(X_train_cv)\n",
    "        train_data_sa.to_csv(self.config.transformed_train_dir / 'train_sa.csv', index=False)\n",
    "        train_data_cv.to_csv(self.config.transformed_train_dir / 'train_cv.csv', index=False)\n",
    "        logger.info(f\"Training data saved: Sa - {train_data_sa.shape}, CV - {train_data_cv.shape}\")\n",
    "\n",
    "        test_data_sa = pd.DataFrame(X_test_sa)\n",
    "        test_data_cv = pd.DataFrame(X_test_cv)\n",
    "        test_data_sa.to_csv(self.config.transformed_test_dir / 'test_sa.csv', index=False)\n",
    "        test_data_cv.to_csv(self.config.transformed_test_dir / 'test_cv.csv', index=False)\n",
    "        logger.info(f\"Testing data saved: Sa - {test_data_sa.shape}, CV - {test_data_cv.shape}\")\n",
    "\n",
    "    def execute(self):\n",
    "        try:\n",
    "            data = self.load_data()\n",
    "            preprocessed_data = self.preprocess_data(data)\n",
    "            X_sa_rfe, X_cv_rfe, y_sa, y_cv = self.feature_engineering(preprocessed_data)\n",
    "            self.train_test_splitting(X_sa_rfe, X_cv_rfe, y_sa, y_cv)\n",
    "\n",
    "            # Create status file\n",
    "            with open(self.config.root_dir / \"status.txt\", \"w\") as f:\n",
    "                f.write(\"Transformation status: True\")\n",
    "\n",
    "            logger.info(\"Data transformation and splitting completed successfully.\")\n",
    "        except Exception as e:\n",
    "            # Create status file with failure status\n",
    "            with open(self.config.root_dir / \"status.txt\", \"w\") as f:\n",
    "                f.write(\"Transformation status: False\")\n",
    "\n",
    "            logger.exception(e)\n",
    "            raise e\n",
    "\n",
    "# Pipeline execution\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data_transformation.execute()\n",
    "except Exception as e:\n",
    "    logger.exception(e)\n",
    "    raise e\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
