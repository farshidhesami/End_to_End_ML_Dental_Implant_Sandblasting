{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from Dental_Implant_Sandblasting import logger\n",
    "from Dental_Implant_Sandblasting.utils.common import read_yaml, create_directories\n",
    "from Dental_Implant_Sandblasting.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH, SCHEMA_FILE_PATH\n",
    "from sklearn.linear_model import Ridge, ElasticNet, BayesianRidge, HuberRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import joblib\n",
    "\n",
    "# Define ModelTrainerConfig dataclass\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path\n",
    "    test_size: float\n",
    "    random_state: int\n",
    "    models: dict\n",
    "    param_grids: dict\n",
    "    alpha: float\n",
    "    l1_ratio: float\n",
    "    target_column: str\n",
    "\n",
    "# Define ConfigurationManager class\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH, schema_filepath=SCHEMA_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "        create_directories([self.config['artifacts_root']])\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config['model_trainer']\n",
    "        params = self.params['model_training']\n",
    "        param_grids = self.params['hyperparameter_tuning']\n",
    "\n",
    "        create_directories([config['root_dir']])\n",
    "\n",
    "        # Debug print statements\n",
    "        print(\"Debug: Entire params dictionary:\")\n",
    "        print(self.params)\n",
    "        print(\"Debug: Keys in params:\")\n",
    "        print(self.params.keys())\n",
    "        print(\"Debug: Contents of params['model_training']:\")\n",
    "        print(params)\n",
    "        print(\"Debug: Keys in params['model_training']:\")\n",
    "        print(params.keys())\n",
    "\n",
    "        try:\n",
    "            alpha = params['models']['elasticnet']['alpha']\n",
    "            l1_ratio = params['models']['elasticnet']['l1_ratio']\n",
    "        except KeyError as e:\n",
    "            logger.error(f\"KeyError: {e} - Check the params.yaml file for the correct structure.\")\n",
    "            raise\n",
    "\n",
    "        target_column = params['target_column']\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=Path(config['root_dir']),\n",
    "            train_data_path=Path(config['train_data_path']),\n",
    "            test_data_path=Path(config['test_data_path']),\n",
    "            test_size=params['test_size'],\n",
    "            random_state=params['random_state'],\n",
    "            models=params['models'],\n",
    "            param_grids=param_grids,\n",
    "            alpha=alpha,\n",
    "            l1_ratio=l1_ratio,\n",
    "            target_column=target_column\n",
    "        )\n",
    "        return model_trainer_config\n",
    "\n",
    "# Define ModelTrainer class\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "        self.models = {\n",
    "            \"Ridge\": Ridge(alpha=self.config.models['ridge']['alpha']),\n",
    "            \"ElasticNet\": ElasticNet(alpha=self.config.alpha, l1_ratio=self.config.l1_ratio),\n",
    "            \"BayesianRidge\": BayesianRidge(),\n",
    "            \"HuberRegressor\": HuberRegressor(epsilon=self.config.models['huber_regressor']['epsilon']),\n",
    "            \"RandomForest\": RandomForestRegressor(random_state=self.config.random_state),\n",
    "            \"GradientBoosting\": GradientBoostingRegressor(random_state=self.config.random_state),\n",
    "            \"SVR\": SVR(),\n",
    "            \"XGBRegressor\": XGBRegressor(random_state=self.config.random_state)\n",
    "        }\n",
    "        self.param_grids = {\n",
    "            'RandomForest': self.config.param_grids['random_forest'],\n",
    "            'GradientBoosting': self.config.param_grids['gradient_boosting'],\n",
    "            'Ridge': self.config.param_grids['ridge'],\n",
    "            'ElasticNet': self.config.param_grids['elasticnet'],\n",
    "            'HuberRegressor': self.config.param_grids['huber'],\n",
    "            'SVR': self.config.param_grids['svr'],\n",
    "            'XGBRegressor': self.config.param_grids['xgboost']\n",
    "        }\n",
    "\n",
    "    def load_data(self):\n",
    "        try:\n",
    "            train_data = pd.read_csv(self.config.train_data_path)\n",
    "            test_data = pd.read_csv(self.config.test_data_path)\n",
    "\n",
    "            X_train = train_data.drop(columns=[self.config.target_column])\n",
    "            y_train = train_data[self.config.target_column]\n",
    "\n",
    "            X_test = test_data.drop(columns=[self.config.target_column])\n",
    "            y_test = test_data[self.config.target_column]\n",
    "\n",
    "            return X_train, y_train, X_test, y_test\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading data: {e}\")\n",
    "            raise\n",
    "\n",
    "    def evaluate_models(self, X_train, y_train):\n",
    "        model_performance = {}\n",
    "\n",
    "        for model_name, model in self.models.items():\n",
    "            logger.info(f\"Training {model_name}...\")\n",
    "            try:\n",
    "                cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "                mae = -cv_scores.mean()\n",
    "\n",
    "                model_performance[model_name] = {\n",
    "                    \"MAE\": mae\n",
    "                }\n",
    "\n",
    "                logger.info(f\"{model_name} - MAE: {mae:.4f}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error training {model_name}: {e}\")\n",
    "\n",
    "        return model_performance\n",
    "\n",
    "    def hyperparameter_tuning(self, X_train, y_train):\n",
    "        best_models = {}\n",
    "\n",
    "        for model_name in self.param_grids.keys():\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=self.models[model_name],\n",
    "                param_grid=self.param_grids[model_name]['param_grid'],\n",
    "                cv=self.config.param_grids['cv'],\n",
    "                scoring=self.config.param_grids['scoring'],\n",
    "                n_jobs=-1,\n",
    "                verbose=2\n",
    "            )\n",
    "            logger.info(f\"Tuning {model_name}...\")\n",
    "            try:\n",
    "                grid_search.fit(X_train, y_train)\n",
    "                best_models[model_name] = grid_search.best_estimator_\n",
    "                logger.info(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error tuning {model_name}: {e}\")\n",
    "\n",
    "        return best_models\n",
    "\n",
    "    def save_best_models(self, best_models):\n",
    "        for model_name, model in best_models.items():\n",
    "            try:\n",
    "                joblib.dump(model, self.config.root_dir / f\"{model_name}.joblib\")\n",
    "                logger.info(f\"Saved best model {model_name} to {self.config.root_dir / f'{model_name}.joblib'}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error saving model {model_name}: {e}\")\n",
    "\n",
    "    def execute(self):\n",
    "        try:\n",
    "            X_train, y_train, X_test, y_test = self.load_data()\n",
    "            model_performance = self.evaluate_models(X_train, y_train)\n",
    "            performance_df = pd.DataFrame(model_performance).T\n",
    "            print(\"\\nModel Performance:\\n\", performance_df)\n",
    "\n",
    "            best_models = self.hyperparameter_tuning(X_train, y_train)\n",
    "\n",
    "            self.save_best_models(best_models)\n",
    "        except Exception as e:\n",
    "            logger.exception(e)\n",
    "            raise e\n",
    "\n",
    "# Pipeline execution\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer = ModelTrainer(config=model_trainer_config)\n",
    "    model_trainer.execute()\n",
    "except Exception as e:\n",
    "    logger.exception(e)\n",
    "    raise e\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
