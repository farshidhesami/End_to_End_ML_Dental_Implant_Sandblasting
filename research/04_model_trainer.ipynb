{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\iNeuron_Projects\\\\End_to_End_ML_Dental_Implant_Sandblasting\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\iNeuron_Projects\\\\End_to_End_ML_Dental_Implant_Sandblasting'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-10 21:12:20,584: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-07-10 21:12:20,664: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-07-10 21:12:20,708: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2024-07-10 21:12:20,720: INFO: common: created directory at: artifacts]\n",
      "[2024-07-10 21:12:20,728: INFO: common: created directory at: artifacts/model_trainer]\n",
      "[2024-07-10 21:12:20,732: ERROR: 1680040719: 'int' object is not subscriptable]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Farshid Hesami\\AppData\\Local\\Temp\\ipykernel_1324\\1680040719.py\", line 228, in <module>\n",
      "    model_trainer = ModelTrainer(config=model_trainer_config)\n",
      "  File \"C:\\Users\\Farshid Hesami\\AppData\\Local\\Temp\\ipykernel_1324\\1680040719.py\", line 89, in __init__\n",
      "    self.param_grids = {key: value['param_grid'] for key, value in self.config.param_grids.items()}\n",
      "  File \"C:\\Users\\Farshid Hesami\\AppData\\Local\\Temp\\ipykernel_1324\\1680040719.py\", line 89, in <dictcomp>\n",
      "    self.param_grids = {key: value['param_grid'] for key, value in self.config.param_grids.items()}\n",
      "TypeError: 'int' object is not subscriptable\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 232\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    231\u001b[0m     logger\u001b[38;5;241m.\u001b[39mexception(e)\n\u001b[1;32m--> 232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[5], line 228\u001b[0m\n\u001b[0;32m    226\u001b[0m     config \u001b[38;5;241m=\u001b[39m ConfigurationManager()\n\u001b[0;32m    227\u001b[0m     model_trainer_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_model_trainer_config()\n\u001b[1;32m--> 228\u001b[0m     model_trainer \u001b[38;5;241m=\u001b[39m \u001b[43mModelTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_trainer_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m     model_trainer\u001b[38;5;241m.\u001b[39mexecute()\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[5], line 89\u001b[0m, in \u001b[0;36mModelTrainer.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRidge\u001b[39m\u001b[38;5;124m\"\u001b[39m: Ridge(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodels[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mridge\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mElasticNet\u001b[39m\u001b[38;5;124m\"\u001b[39m: ElasticNet(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39malpha, l1_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39ml1_ratio),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGBRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m: XGBRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[0;32m     88\u001b[0m }\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grids \u001b[38;5;241m=\u001b[39m {key: value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam_grid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mparam_grids\u001b[38;5;241m.\u001b[39mitems()}\n",
      "Cell \u001b[1;32mIn[5], line 89\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRidge\u001b[39m\u001b[38;5;124m\"\u001b[39m: Ridge(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodels[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mridge\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mElasticNet\u001b[39m\u001b[38;5;124m\"\u001b[39m: ElasticNet(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39malpha, l1_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39ml1_ratio),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGBRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m: XGBRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[0;32m     88\u001b[0m }\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grids \u001b[38;5;241m=\u001b[39m {key: \u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparam_grid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mparam_grids\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from Dental_Implant_Sandblasting import logger\n",
    "from Dental_Implant_Sandblasting.utils.common import read_yaml, create_directories\n",
    "from Dental_Implant_Sandblasting.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH, SCHEMA_FILE_PATH\n",
    "from sklearn.linear_model import Ridge, ElasticNet, BayesianRidge, HuberRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "# Define ModelTrainerConfig dataclass\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path\n",
    "    test_size: float\n",
    "    random_state: int\n",
    "    models: dict\n",
    "    param_grids: dict\n",
    "    alpha: float\n",
    "    l1_ratio: float\n",
    "    target_column: str\n",
    "    cv: int\n",
    "    scoring: str\n",
    "\n",
    "# Define ConfigurationManager class\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH, schema_filepath=SCHEMA_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "        create_directories([self.config['artifacts_root']])\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config['model_trainer']\n",
    "        params = self.params['model_training']\n",
    "        param_grids = self.params['hyperparameter_tuning']\n",
    "\n",
    "        create_directories([config['root_dir']])\n",
    "\n",
    "        try:\n",
    "            alpha = params['models']['elasticnet']['alpha']\n",
    "            l1_ratio = params['models']['elasticnet']['l1_ratio']\n",
    "        except KeyError as e:\n",
    "            logger.error(f\"KeyError: {e} - Check the params.yaml file for the correct structure.\")\n",
    "            raise\n",
    "\n",
    "        target_column = params['target_column']\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=Path(config['root_dir']),\n",
    "            train_data_path=Path(config['train_data_path']),\n",
    "            test_data_path=Path(config['test_data_path']),\n",
    "            test_size=params['test_size'],\n",
    "            random_state=params['random_state'],\n",
    "            models=params['models'],\n",
    "            param_grids=param_grids,\n",
    "            alpha=alpha,\n",
    "            l1_ratio=l1_ratio,\n",
    "            target_column=target_column,\n",
    "            cv=param_grids['cv'],\n",
    "            scoring=param_grids['scoring']\n",
    "        )\n",
    "        return model_trainer_config\n",
    "\n",
    "# Define ModelTrainer class\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "        self.models = {\n",
    "            \"Ridge\": Ridge(alpha=self.config.models['ridge']['alpha']),\n",
    "            \"ElasticNet\": ElasticNet(alpha=self.config.alpha, l1_ratio=self.config.l1_ratio),\n",
    "            \"BayesianRidge\": BayesianRidge(),\n",
    "            \"HuberRegressor\": HuberRegressor(epsilon=self.config.models['huber_regressor']['epsilon'], max_iter=self.config.models['huber_regressor']['max_iter']),\n",
    "            \"RandomForest\": RandomForestRegressor(random_state=self.config.random_state),\n",
    "            \"GradientBoosting\": GradientBoostingRegressor(random_state=self.config.random_state),\n",
    "            \"SVR\": SVR(),\n",
    "            \"XGBRegressor\": XGBRegressor(random_state=self.config.random_state)\n",
    "        }\n",
    "        self.param_grids = {key: value['param_grid'] for key, value in self.config.param_grids.items()}\n",
    "\n",
    "    def load_data(self):\n",
    "        try:\n",
    "            train_data = pd.read_csv(self.config.train_data_path)\n",
    "            test_data = pd.read_csv(self.config.test_data_path)\n",
    "\n",
    "            X_train = train_data.drop(columns=[self.config.target_column])\n",
    "            y_train = train_data[self.config.target_column]\n",
    "\n",
    "            X_test = test_data.drop(columns=[self.config.target_column])\n",
    "            y_test = test_data[self.config.target_column]\n",
    "\n",
    "            return X_train, y_train, X_test, y_test\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading data: {e}\")\n",
    "            raise\n",
    "\n",
    "    def evaluate_models(self, X_train, y_train):\n",
    "        model_performance = {}\n",
    "\n",
    "        for model_name, model in self.models.items():\n",
    "            logger.info(f\"Training {model_name}...\")\n",
    "            try:\n",
    "                cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "                mae = -cv_scores.mean()\n",
    "\n",
    "                model_performance[model_name] = {\n",
    "                    \"MAE\": mae\n",
    "                }\n",
    "\n",
    "                logger.info(f\"{model_name} - MAE: {mae:.4f}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error training {model_name}: {e}\")\n",
    "\n",
    "        return model_performance\n",
    "\n",
    "    def hyperparameter_tuning(self, X_train, y_train):\n",
    "        best_models = {}\n",
    "\n",
    "        for model_name in self.param_grids.keys():\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=self.models[model_name],\n",
    "                param_grid=self.param_grids[model_name],\n",
    "                cv=self.config.cv,\n",
    "                scoring=self.config.scoring,\n",
    "                n_jobs=-1,\n",
    "                verbose=2\n",
    "            )\n",
    "            logger.info(f\"Tuning {model_name}...\")\n",
    "            try:\n",
    "                grid_search.fit(X_train, y_train)\n",
    "                best_models[model_name] = grid_search.best_estimator_\n",
    "                logger.info(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error tuning {model_name}: {e}\")\n",
    "\n",
    "        return best_models\n",
    "\n",
    "    def evaluate_best_models(self, best_models, X_test, y_test):\n",
    "        performance_metrics = {}\n",
    "\n",
    "        for model_name, model in best_models.items():\n",
    "            try:\n",
    "                y_pred = model.predict(X_test)\n",
    "                mae = mean_absolute_error(y_test, y_pred)\n",
    "                rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "                r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "                performance_metrics[model_name] = {\n",
    "                    \"MAE\": mae,\n",
    "                    \"RMSE\": rmse,\n",
    "                    \"R2\": r2\n",
    "                }\n",
    "\n",
    "                logger.info(f\"{model_name} - Test MAE: {mae:.4f}\")\n",
    "                logger.info(f\"{model_name} - Test RMSE: {rmse:.4f}\")\n",
    "                logger.info(f\"{model_name} - Test R2: {r2:.4f}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error evaluating {model_name}: {e}\")\n",
    "\n",
    "        return performance_metrics\n",
    "\n",
    "    def save_best_models(self, best_models):\n",
    "        for model_name, model in best_models.items():\n",
    "            try:\n",
    "                joblib.dump(model, self.config.root_dir / f\"{model_name}.joblib\")\n",
    "                logger.info(f\"Saved best model {model_name} to {self.config.root_dir / f'{model_name}.joblib'}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error saving model {model_name}: {e}\")\n",
    "\n",
    "    def execute(self):\n",
    "        try:\n",
    "            X_train, y_train, X_test, y_test = self.load_data()\n",
    "            model_performance = self.evaluate_models(X_train, y_train)\n",
    "            performance_df = pd.DataFrame(model_performance).T\n",
    "            print(\"\\nModel Performance:\\n\", performance_df)\n",
    "\n",
    "            best_models = self.hyperparameter_tuning(X_train, y_train)\n",
    "            performance_metrics = self.evaluate_best_models(best_models, X_test, y_test)\n",
    "\n",
    "            best_hyperparameters = {model_name: model.get_params() for model_name, model in best_models.items()}\n",
    "            print(\"\\nBest Hyperparameters:\\n\", best_hyperparameters)\n",
    "            print(\"\\nPerformance Metrics:\\n\", performance_metrics)\n",
    "\n",
    "            self.save_best_models(best_models)\n",
    "\n",
    "            # Visualizations\n",
    "            metrics_df = pd.DataFrame(performance_metrics).T\n",
    "\n",
    "            plt.figure(figsize=(14, 6))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            sns.barplot(x=metrics_df.index, y=[metrics_df['MAE'][model] for model in metrics_df.index])\n",
    "            plt.title('MAE for Best Models')\n",
    "            plt.ylabel('Mean Absolute Error')\n",
    "            plt.xlabel('Model')\n",
    "\n",
    "            plt.subplot(1, 3, 2)\n",
    "            sns.barplot(x=metrics_df.index, y=[metrics_df['RMSE'][model] for model in metrics_df.index])\n",
    "            plt.title('RMSE for Best Models')\n",
    "            plt.ylabel('Root Mean Squared Error')\n",
    "            plt.xlabel('Model')\n",
    "\n",
    "            plt.subplot(1, 3, 3)\n",
    "            sns.barplot(x=metrics_df.index, y=[metrics_df['R2'][model] for model in metrics_df.index])\n",
    "            plt.title('R2 for Best Models')\n",
    "            plt.ylabel('R-Squared')\n",
    "            plt.xlabel('Model')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            logger.exception(e)\n",
    "            raise e\n",
    "\n",
    "# Pipeline execution\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer = ModelTrainer(config=model_trainer_config)\n",
    "    model_trainer.execute()\n",
    "except Exception as e:\n",
    "    logger.exception(e)\n",
    "    raise e\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
