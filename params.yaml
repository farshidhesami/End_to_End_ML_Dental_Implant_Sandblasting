# Parameters for data preprocessing
data_preprocessing:
  imputation_strategy: "mean"

# Parameters for feature engineering
data_transformation:
  polynomial_features_degree: 2
  scaling_method: "StandardScaler"
  test_size: 0.2
  random_state: 42
  lasso_max_iter: 10000

# Parameters for model training
model_training:
  target_column: 'Result (1=Passed, 0=Failed)'
  models:
    ridge:
      alpha: 100.0
    elasticnet:
      alpha: 0.1
      l1_ratio: 0.5
    bayesian_ridge: {}
    huber_regressor:
      alpha: 0.0001
      epsilon: 1.35
      max_iter: 10000  # Increased max_iter
      tol: 0.000001
      warm_start: False
    random_forest:
      n_estimators: 50
      max_depth: 10
      min_samples_leaf: 1
      min_samples_split: 10
      random_state: 42
    gradient_boosting:
      n_estimators: 50
      learning_rate: 0.2
      max_depth: 7
    svr:
      C: 0.1
      epsilon: 0.01
      kernel: "rbf"
    xgboost:
      objective: 'reg:squarederror'
      n_estimators: 200
      learning_rate: 0.1
      max_depth: 5
      subsample: 1.0

# Parameters for hyperparameter tuning
hyperparameter_tuning:
  cv: 5
  scoring: "neg_mean_absolute_error"
  ridge:
    param_grid:
      alpha: [0.1, 1.0, 10.0, 100.0]
  elasticnet:
    param_grid:
      alpha: [0.1, 1.0, 10.0]
      l1_ratio: [0.1, 0.5, 0.9]
  huber_regressor:
    param_grid:
      alpha: [0.0001, 0.001, 0.01]
      epsilon: [1.35, 1.5, 1.75]
      max_iter: [1000, 2000, 5000, 10000]  # Ensure increased max_iter is also here
      tol: [0.000001, 0.00001]  # Ensure adjusted tolerance is also here
  svr:
    param_grid:
      C: [0.1, 1.0, 10.0]
      epsilon: [0.01, 0.1, 1.0]
      kernel: ["linear", "rbf"]
  random_forest:
    param_grid:
      n_estimators: [50, 100, 200]
      max_depth: [10, 20, null]  # Replace 'None' with null
      min_samples_split: [2, 5, 10]
      min_samples_leaf: [1, 2, 4]
  gradient_boosting:
    param_grid:
      n_estimators: [50, 100, 200]
      learning_rate: [0.01, 0.1, 0.2]
      max_depth: [3, 5, 7]
  xgboost:
    param_grid:
      n_estimators: [50, 100, 200]
      learning_rate: [0.01, 0.1, 0.2]
      max_depth: [3, 5, 7]
